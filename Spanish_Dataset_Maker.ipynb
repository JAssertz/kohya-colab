{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmCPmqFL6hCQ"
      },
      "source": [
        "# üìä Preparador de Lora de Hollowstrawberry\n",
        "\n",
        "Basado en el trabajo de [Kohya_ss](https://github.com/kohya-ss/sd-scripts) y [Linaqruf](https://colab.research.google.com/github/Linaqruf/kohya-trainer/blob/main/kohya-LoRA-dreambooth.ipynb#scrollTo=-Z4w3lfFKLjr). ¬°Gracias!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDoUi4JM_lz9"
      },
      "source": [
        "### ‚≠ï Disclaimer\n",
        "The purpose of this document is to research bleeding-edge technologies in the field of machine learning.  \n",
        "Please read and follow the [Google Colab guidelines](https://research.google.com/colaboratory/faq.html) and its [Terms of Service](https://research.google.com/colaboratory/tos_v3.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BJTp5PVN_q-"
      },
      "source": [
        "| |GitHub|üá¨üáß English|üá™üá∏ Spanish|\n",
        "|:--|:-:|:-:|:-:|\n",
        "| üè† **Origen** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab) | | |\n",
        "| üìä **Dataset Maker** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab/blob/main/Dataset_Maker.ipynb) | [![Open in Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Dataset_Maker.ipynb) | [![Abrir en Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge-spanish.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Spanish_Dataset_Maker.ipynb) |\n",
        "| ‚≠ê **Lora Trainer** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer.ipynb) | [![Open in Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer.ipynb) | [![Abrir en Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge-spanish.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Spanish_Lora_Trainer.ipynb) |\n",
        "| üåü **XL Lora Trainer** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer_XL.ipynb) | [![Open in Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer_XL.ipynb) |  |\n",
        "| üåü **Legacy XL Trainer** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer_XL_Legacy.ipynb) | [![Open in Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer_XL_Legacy.ipynb) |  |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cBa7KdewQ4BU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from IPython import get_ipython\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "COLAB = True\n",
        "\n",
        "if COLAB:\n",
        "  from google.colab.output import clear as clear_output\n",
        "else:\n",
        "  from IPython.display import clear_output\n",
        "\n",
        "#@title ## üö© Empezar aqu√≠\n",
        "\n",
        "#@markdown ### 1Ô∏è‚É£  Inicio\n",
        "#@markdown Esta celda cargar√° algunos requerimientos y crear√° las carpetas correspondientes en tu Google Drive. <p>\n",
        "#@markdown Tu nombre de proyecto ser√° la carpeta donde trabajaremos. No se permiten espacios.\n",
        "nombre_proyecto = \"\" #@param {type:\"string\"}\n",
        "project_name = nombre_proyecto.strip()\n",
        "#@markdown La estructura de carpetas no importa y es por comodidad. Aseg√∫rate de siempre elegir la misma. Me gusta organizar por proyecto.\n",
        "estructura_de_carpetas = \"Organizar por proyecto (MyDrive/Loras/nombre_proyecto/dataset)\" #@param [\"Organizar por categor√≠a (MyDrive/lora_training/datasets/nombre_proyecto)\", \"Organizar por proyecto (MyDrive/Loras/nombre_proyecto/dataset)\"]\n",
        "folder_structure = estructura_de_carpetas\n",
        "\n",
        "if not project_name or any(c in project_name for c in \" .()\\\"'\\\\\") or project_name.count(\"/\") > 1:\n",
        "  print(\"Por favor elige un nombre v√°lido.\")\n",
        "else:\n",
        "  if COLAB and not os.path.exists('/content/drive'):\n",
        "    from google.colab import drive\n",
        "    print(\"üìÇ Conectando a Google Drive...\")\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "  project_base = project_name if \"/\" not in project_name else project_name[:project_name.rfind(\"/\")]\n",
        "  project_subfolder = project_name if \"/\" not in project_name else project_name[project_name.rfind(\"/\")+1:]\n",
        "\n",
        "  root_dir = \"/content\" if COLAB else \"~/Loras\"\n",
        "  deps_dir = os.path.join(root_dir, \"deps\")\n",
        "\n",
        "  if \"/Loras\" in folder_structure:\n",
        "    main_dir      = os.path.join(root_dir, \"drive/MyDrive/Loras\") if COLAB else root_dir\n",
        "    config_folder = os.path.join(main_dir, project_base)\n",
        "    images_folder = os.path.join(main_dir, project_base, \"dataset\")\n",
        "    if \"/\" in project_name:\n",
        "      images_folder = os.path.join(images_folder, project_subfolder)\n",
        "  else:\n",
        "    main_dir      = os.path.join(root_dir, \"drive/MyDrive/lora_training\") if COLAB else root_dir\n",
        "    config_folder = os.path.join(main_dir, \"config\", project_name)\n",
        "    images_folder = os.path.join(main_dir, \"datasets\", project_name)\n",
        "\n",
        "  for dir in [main_dir, deps_dir, images_folder, config_folder]:\n",
        "    os.makedirs(dir, exist_ok=True)\n",
        "\n",
        "  print(f\"‚úÖ ¬°Proyecto {project_name} listo!\")\n",
        "  step1_installed_flag = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "afu5dCKTV31E"
      },
      "outputs": [],
      "source": [
        "if \"step1_installed_flag\" not in globals():\n",
        "  raise Exception(\"Por favor usa el paso 1 primero.\")\n",
        "\n",
        "import json\n",
        "import time\n",
        "from urllib.request import urlopen, Request\n",
        "\n",
        "#@markdown ### 2Ô∏è‚É£ Obtener im√°genes\n",
        "\n",
        "#@markdown Obtendremos im√°genes de la galer√≠a de anime llamada [Gelbooru](https://gelbooru.com/). Las im√°genes se organizan por miles de tags que describen todo acerca de una imagen. <p>\n",
        "#@markdown * Si quieres encontrar y usar tus propias im√°genes, ponlas dentro de la carpeta `Loras/nombre_proyecto/dataset` en tu Google Drive.\n",
        "#@markdown * Si quieres descargar capturas de episodios de anime, existe [este otro colab de otra persona](https://colab.research.google.com/drive/1oBSntB40BKzNmKceXUlkXzujzdQw-Ci7) aunque aquel es m√°s complicado.\n",
        "\n",
        "#@markdown Hasta 1000 im√°genes se descargar√°n en un minuto, no debes abusar de ello. <p>\n",
        "#@markdown Tus tags deben ser relevantes para lo que desees entrenar, y excluir elementos no deseados (el contenido expl√≠cito puede hacer m√°s dif√≠cil el entrenamiento).\n",
        "#@markdown Las palabras van separadas por guionbajos, las tags van separadas por espacios, y usa - para excluir esa tag. Tambi√©n puedes incluir una puntuaci√≥n m√≠nima: `score:>10`\n",
        "tags = \"1girl -sex -greyscale -monochrome\" #@param {type:\"string\"}\n",
        "#markdown Si una imagen supera esta resoluci√≥n, se descargar√° una versi√≥n m√°s peque√±a.\n",
        "max_resolution = 3072 #param {type:\"slider\", min:1024, max:8196, step:1024}\n",
        "#markdown Posts with a parent post are often minor variations of the same image.\n",
        "include_posts_with_parent = True #param {type:\"boolean\"}\n",
        "\n",
        "tags = tags.replace(\" \", \"+\")\\\n",
        "           .replace(\"(\", \"%28\")\\\n",
        "           .replace(\")\", \"%29\")\\\n",
        "           .replace(\":\", \"%3a\")\\\n",
        "\n",
        "url = \"https://gelbooru.com/index.php?page=dapi&json=1&s=post&q=index&limit=100&tags={}\".format(tags)\n",
        "user_agent = \"Mozilla/5.0 AppleWebKit/537.36 (KHTML, like Gecko; compatible; Googlebot/2.1; +http://www.google.com/bot.html) Chrome/93.0.4577.83 Safari/537.36\"\n",
        "limit = 100 # hardcoded by gelbooru\n",
        "total_limit = 1000 # you can edit this if you want but I wouldn't recommend it\n",
        "supported_types = (\".png\", \".jpg\", \".jpeg\")\n",
        "\n",
        "def ubuntu_deps():\n",
        "  print(\"üè≠ Instalando...\\n\")\n",
        "  !apt update\n",
        "  !apt -y install aria2\n",
        "  return not get_ipython().__dict__['user_ns']['_exit_code']\n",
        "\n",
        "if \"step2_installed_flag\" not in globals():\n",
        "  if ubuntu_deps():\n",
        "    clear_output()\n",
        "    step2_installed_flag = True\n",
        "  else:\n",
        "    print(\"‚ùå Error en la instalaci√≥n, intentando continuar...\")\n",
        "\n",
        "def get_json(url):\n",
        "  with urlopen(Request(url, headers={\"User-Agent\": user_agent})) as page:\n",
        "    return json.load(page)\n",
        "\n",
        "def filter_images(data):\n",
        "  return [p[\"file_url\"] if p[\"width\"]*p[\"height\"] <= max_resolution**2 else p[\"sample_url\"]\n",
        "          for p in data[\"post\"]\n",
        "          if (p[\"parent_id\"] == 0 or include_posts_with_parent)\n",
        "          and p[\"file_url\"].lower().endswith(supported_types)]\n",
        "\n",
        "def download_images():\n",
        "  data = get_json(url)\n",
        "  count = data[\"@attributes\"][\"count\"]\n",
        "\n",
        "  if count == 0:\n",
        "    print(\"üì∑ No se encontraron resultados.\")\n",
        "    return\n",
        "\n",
        "  print(f\"üéØ Se encontraron {count} resultados\")\n",
        "  test_url = \"https://gelbooru.com/index.php?page=post&s=list&tags={}\".format(tags)\n",
        "  display(Markdown(f\"[¬°Click aqu√≠ para verlos en tu navegador!]({test_url})\"))\n",
        "  print (f\"üîΩ Se descargar√° en {images_folder.replace('/content/drive/', '')} (Aparecer√° una confirmaci√≥n aqu√≠ abajo, sino vuelve a correr esta celda)\")\n",
        "  inp = input(\"‚ùì Escribe \\\"si\\\" para continuar con la descarga: \")\n",
        "\n",
        "  if inp.lower().strip() not in (\"si\", \"s√≠\"):\n",
        "    print(\"‚ùå Download cancelled\")\n",
        "    return\n",
        "\n",
        "  print(\"üì© Obteniendo lista de im√°genes...\")\n",
        "\n",
        "  image_urls = set()\n",
        "  image_urls = image_urls.union(filter_images(data))\n",
        "  for i in range(total_limit // limit):\n",
        "    count -= limit\n",
        "    if count <= 0:\n",
        "      break\n",
        "    time.sleep(0.1)\n",
        "    image_urls = image_urls.union(filter_images(get_json(url+f\"&pid={i+1}\")))\n",
        "\n",
        "  scrape_file = os.path.join(config_folder, f\"scrape_{project_subfolder}.txt\")\n",
        "  with open(scrape_file, \"w\") as f:\n",
        "    f.write(\"\\n\".join(image_urls))\n",
        "\n",
        "  print(f\"üåê Enlaces guardados a {scrape_file}\\n\\nüîÅ Descargando im√°genes ...\\n\")\n",
        "  old_img_count = len([f for f in os.listdir(images_folder) if f.lower().endswith(supported_types)])\n",
        "\n",
        "  os.chdir(images_folder)\n",
        "  !aria2c --console-log-level=warn -c -x 16 -k 1M -s 16 -i {scrape_file}\n",
        "\n",
        "  new_img_count = len([f for f in os.listdir(images_folder) if f.lower().endswith(supported_types)])\n",
        "  print(f\"\\n‚úÖ Se han descargado {new_img_count - old_img_count} im√°genes.\")\n",
        "\n",
        "download_images()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "b218DEEMpwzB"
      },
      "outputs": [],
      "source": [
        "if \"step1_installed_flag\" not in globals():\n",
        "  raise Exception(\"Please run step 1 first!\")\n",
        "\n",
        "#@markdown ### 3Ô∏è‚É£ Filtrar tus im√°genes\n",
        "#@markdown Vamos a detectar y borrar im√°genes duplicadas usando la IA de FiftyOne. <p>\n",
        "#@markdown Porcentaje de similaridad para que dos im√°genes se consideren iguales. Recomiendo 0.97 to 0.99:\n",
        "similaridad = 0.985 #@param {type:\"number\"}\n",
        "similarity_threshold = similaridad\n",
        "#@markdown Puedes elegir entre simplemente borrar los duplicados, o adicionalmente abrir un √°rea interactiva bajo esta celda para visualizar tus im√°genes y marcar las que quieras con `delete` que luego ser√°n borradas. <p>\n",
        "#@markdown Si el √°rea interactiva no aparece o est√° vac√≠a, intenta activar las cookies y quitar la protecci√≥n contra rastreo para la p√°gina de Google Colab en tu navegador.\n",
        "#@markdown Para guardar los cambios del √°rea interactiva tendr√°s que apretar Enter en la caja de texto que aparecer√° sobre el area interactiva.<p>\n",
        "accion = \"Borrar duplicados\" #@param [\"Borrar duplicados\",\"Marcar duplicados y abrir area interactiva\",\"Abrir area interactiva\"]\n",
        "action = accion\n",
        "\n",
        "open_in_new_tab = False\n",
        "ngrok_token = \"\"\n",
        "\n",
        "\n",
        "os.chdir(root_dir)\n",
        "model_name = \"clip-vit-base32-torch\"\n",
        "supported_types = (\".png\", \".jpg\", \".jpeg\")\n",
        "img_count = len(os.listdir(images_folder))\n",
        "batch_size = min(250, img_count)\n",
        "\n",
        "if \"step3_installed_flag\" not in globals():\n",
        "  print(\"üè≠ Instalando dependencias...\\n\")\n",
        "  !pip -q install fiftyone ftfy pyngrok\n",
        "  !pip -q install fiftyone-db-ubuntu2204\n",
        "  if not get_ipython().__dict__['user_ns']['_exit_code']:\n",
        "    clear_output()\n",
        "    step3_installed_flag = True\n",
        "  else:\n",
        "    print(\"‚ùå Error de instalaci√≥n, intentando continuar de todas formas...\")\n",
        "\n",
        "os.environ[\"FIFTYONE_SERVER\"] = \"0\"\n",
        "import numpy as np\n",
        "import fiftyone as fo\n",
        "import fiftyone.zoo as foz\n",
        "from fiftyone import ViewField as F\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from pyngrok import ngrok, conf\n",
        "from portpicker import pick_unused_port\n",
        "\n",
        "non_images = [f for f in os.listdir(images_folder) if not f.lower().endswith(supported_types)]\n",
        "if non_images:\n",
        "  print(f\"üí• Error: El archivo {non_images[0]} no es una imagen - Esto no est√° permitido. Usa los Extras m√°s abajo para borrar los archivos que no sean im√°genes.\")\n",
        "elif img_count == 0:\n",
        "  print(f\"üí• Error: No se encontraron im√°genes en {images_folder}\")\n",
        "else:\n",
        "  print(\"\\nüíø Analizando dataset...\\n\")\n",
        "  dataset = fo.Dataset.from_dir(images_folder, dataset_type=fo.types.ImageDirectory)\n",
        "  if \"duplicados\" in action:\n",
        "    model = foz.load_zoo_model(model_name)\n",
        "    embeddings = dataset.compute_embeddings(model, batch_size=batch_size)\n",
        "\n",
        "    batch_embeddings = np.array_split(embeddings, batch_size)\n",
        "    similarity_matrices = []\n",
        "    max_size_x = max(array.shape[0] for array in batch_embeddings)\n",
        "    max_size_y = max(array.shape[1] for array in batch_embeddings)\n",
        "\n",
        "    for i, batch_embedding in enumerate(batch_embeddings):\n",
        "      similarity = cosine_similarity(batch_embedding)\n",
        "      #Pad 0 for np.concatenate\n",
        "      padded_array = np.zeros((max_size_x, max_size_y))\n",
        "      padded_array[0:similarity.shape[0], 0:similarity.shape[1]] = similarity\n",
        "      similarity_matrices.append(padded_array)\n",
        "\n",
        "    similarity_matrix = np.concatenate(similarity_matrices, axis=0)\n",
        "    similarity_matrix = similarity_matrix[0:embeddings.shape[0], 0:embeddings.shape[0]]\n",
        "\n",
        "    similarity_matrix = cosine_similarity(embeddings)\n",
        "    similarity_matrix -= np.identity(len(similarity_matrix))\n",
        "\n",
        "    dataset.match(F(\"max_similarity\") > similarity_threshold)\n",
        "    dataset.tags = [\"delete\", \"has_duplicates\"]\n",
        "\n",
        "    id_map = [s.id for s in dataset.select_fields([\"id\"])]\n",
        "    samples_to_remove = set()\n",
        "    samples_to_keep = set()\n",
        "\n",
        "    for idx, sample in enumerate(dataset):\n",
        "      if sample.id not in samples_to_remove:\n",
        "        # Keep the first instance of two duplicates\n",
        "        samples_to_keep.add(sample.id)\n",
        "\n",
        "        dup_idxs = np.where(similarity_matrix[idx] > similarity_threshold)[0]\n",
        "        for dup in dup_idxs:\n",
        "            # We kept the first instance so remove all other duplicates\n",
        "            samples_to_remove.add(id_map[dup])\n",
        "\n",
        "        if len(dup_idxs) > 0:\n",
        "            sample.tags.append(\"has_duplicates\")\n",
        "            sample.save()\n",
        "      else:\n",
        "        sample.tags.append(\"delete\")\n",
        "        sample.save()\n",
        "\n",
        "    sidebar_groups = fo.DatasetAppConfig.default_sidebar_groups(dataset)\n",
        "    for group in sidebar_groups[1:]:\n",
        "      group.expanded = False\n",
        "    dataset.app_config.sidebar_groups = sidebar_groups\n",
        "    dataset.save()\n",
        "\n",
        "  if \"interactiva\" in action:\n",
        "    clear_output()\n",
        "    os.environ[\"FIFTYONE_SERVER\"] = \"1\"\n",
        "    port = pick_unused_port()\n",
        "    session = fo.launch_app(dataset, port=port, auto=not open_in_new_tab)\n",
        "    if open_in_new_tab:\n",
        "      conf.get_default().auth_token = ngrok_token\n",
        "      public_url = ngrok.connect(port).public_url\n",
        "      print(f\"üü¢ Sesi√≥n abierrta en {public_url}\")\n",
        "\n",
        "    print(\"‚ùó Espera un minuto para que cargue la sesi√≥n, sino, revisa las instrucciones arriba.\")\n",
        "    print(\"‚ùó Cuando est√© listo, ver√°s una cuadr√≠cula con tus im√°genes.\")\n",
        "    print(\"‚ùó A la izquierda puedes activar \\\"sample tags\\\" para ver las im√°genes que est√°n marcadas.\")\n",
        "    print(\"‚ùó Puedes marcar las im√°genes que quieras tras haberlas seleccionado, poniendo un tag llamado \\\"delete\\\" en la parte superior.\")\n",
        "    input(\"‚≠ï Cuando est√©s listo, debes guardar los cambios enviando Enter en esta caja de texto: \")\n",
        "\n",
        "    print(\"üíæ Saving...\")\n",
        "\n",
        "  marked = [s for s in dataset if \"delete\" in s.tags]\n",
        "  dataset.delete_samples(marked)\n",
        "  previous_folder = images_folder[:images_folder.rfind(\"/\")]\n",
        "  dataset.export(export_dir=os.path.join(images_folder, project_subfolder), dataset_type=fo.types.ImageDirectory)\n",
        "\n",
        "  temp_suffix = \"_temp\"\n",
        "  !mv {images_folder} {images_folder}{temp_suffix}\n",
        "  !mv {images_folder}{temp_suffix}/{project_subfolder} {images_folder}\n",
        "  !rm -r {images_folder}{temp_suffix}\n",
        "\n",
        "  if \"interactiva\" in action:\n",
        "    session.refresh()\n",
        "    fo.close_app()\n",
        "    clear_output()\n",
        "\n",
        "  print(f\"\\n‚úÖ {len(marked)} im√°genes han sido borradas. Ahora tienes {len(os.listdir(images_folder))} im√°genes.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "sl4FD7Mz-uea"
      },
      "outputs": [],
      "source": [
        "if \"step1_installed_flag\" not in globals():\n",
        "  raise Exception(\"Por favor corre el paso 1 primero!\")\n",
        "\n",
        "#@markdown ### 4Ô∏è‚É£ Generar descripciones\n",
        "#@markdown Usaremos inteligencia artificial para describir tus im√°genes, espec√≠ficamente [Waifu Diffusion](https://huggingface.co/SmilingWolf/wd-eva02-large-tagger-v3) en el caso de anime (etiquetas/tags) y [BLIP](https://huggingface.co/spaces/Salesforce/BLIP) en el caso de fotograf√≠as (subt√≠tulos/captions) <p>\n",
        "#@markdown Estas descripciones que van junto a tus im√°genes mejoran notablemente la calidad de tu Lora a la hora de entrenar. El proceso demora 5 minutes en instalar y 5 minutos m√°s para describir 1000 im√°genes. Recorre todas las subcarpetas si existen. <p>\n",
        "metodo = \"Tags de Anime\" #@param [\"Tags de Anime\", \"Descripciones de Fotos\"]\n",
        "method = metodo\n",
        "#@markdown **Anime:** Usar ambos taggers es m√°s preciso que uno o el otro. Menor umbral generar√° m√°s tags, prueba 0.25 para conceptos y 0.50 para estilos. Deber√≠as incluir nombres de personajes si no est√°s entrenando un personaje.\n",
        "tagger = \"Ambos\" #@param [\"Ambos\",\"SmilingWolf/wd-eva02-large-tagger-v3\",\"SmilingWolf/wd-vit-large-tagger-v3\"]\n",
        "umbral = 0.25 #@param {type:\"slider\", min:0.0, max:1.0, step:0.01}\n",
        "tag_threshold = umbral\n",
        "tags_no_permitidas = \"virtual youtuber, parody, style parody, official alternate costume, official alternate hairstyle, official alternate hair length, alternate costume, alternate hairstyle, alternate hair length, alternate hair color\" #@param {type:\"string\"}\n",
        "blacklist_tags = tags_no_permitidas\n",
        "nombres_de_personajes = False #@param {type:\"boolean\"}\n",
        "include_character_names = nombres_de_personajes\n",
        "#@markdown **Fotograf√≠as:** El m√≠nmimo y m√°ximo largo de cada subt√≠tulo (medido en tokens/palabras).\n",
        "largo_minimo = 10 #@param {type:\"number\"}\n",
        "caption_min = largo_minimo\n",
        "largo_maximo = 75 #@param {type:\"number\"}\n",
        "caption_max = largo_maximo\n",
        "\n",
        "character_threshold = tag_threshold if include_character_names else 1.1\n",
        "undesired_tags = '\"' + ','.join([t.strip() for t in blacklist_tags.split(\",\") if t.strip()]) + '\"'\n",
        "\n",
        "kohya_dir = \"/content/kohya\"\n",
        "venv_python = os.path.join(kohya_dir, \"venv/bin/python\")\n",
        "venv_pip = os.path.join(kohya_dir, \"venv/bin/pip\")\n",
        "\n",
        "if \"step4_installed_flag\" not in globals():\n",
        "  print(\"\\nüè≠ Instalando dependencias...\\n\")\n",
        "  !apt update\n",
        "  !apt install -y python3.10-venv -qq\n",
        "  !git clone https://github.com/kohya-ss/sd-scripts {kohya_dir}\n",
        "  os.chdir(kohya_dir)\n",
        "  !git reset --hard e89653975ddf429cdf0c0fd268da0a5a3e8dba1f\n",
        "  !python3.10 -m venv venv\n",
        "  !{venv_pip} install -r requirements.txt\n",
        "  !{venv_pip} install fairscale==0.4.13 timm==0.6.12\n",
        "  !{venv_pip} install onnx onnxruntime-gpu==1.20.1 --extra-index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-12/pypi/simple/\n",
        "  !{venv_pip} uninstall -y rich\n",
        "  step4_installed_flag = True\n",
        "\n",
        "print(\"\\nüö∂‚Äç‚ôÇÔ∏è Corriendo programa...\\n\")\n",
        "os.chdir(kohya_dir)\n",
        "\n",
        "if \"Anime\" in method:\n",
        "  tagger_models = [\n",
        "    \"SmilingWolf/wd-eva02-large-tagger-v3\",\n",
        "    \"SmilingWolf/wd-vit-large-tagger-v3\"\n",
        "  ] if tagger == \"Ambos\" else [tagger]\n",
        "\n",
        "  for i, tagger_model in enumerate(tagger_models):\n",
        "    append_tags = \"--append_tags\" if i > 0 else \"\"\n",
        "    !{venv_python} finetune/tag_images_by_wd14_tagger.py \\\n",
        "      {images_folder} \\\n",
        "      --repo_id={tagger_model} \\\n",
        "      --general_threshold={tag_threshold} \\\n",
        "      --character_threshold={character_threshold} \\\n",
        "      --batch_size=8 \\\n",
        "      --max_data_loader_n_workers=2 \\\n",
        "      --caption_extension=.txt \\\n",
        "      --undesired_tags {undesired_tags} \\\n",
        "      --onnx --recursive --remove_underscore {append_tags}\n",
        "\n",
        "  if not get_ipython().__dict__['user_ns']['_exit_code']:\n",
        "    # Count tags\n",
        "    from collections import Counter\n",
        "    text_files = []\n",
        "    for root, dirs, files in os.walk(images_folder):\n",
        "      for file in files:\n",
        "        if file.lower().endswith(\".txt\"):\n",
        "          text_files.append(os.path.join(root, file))\n",
        "    top_tags = Counter()\n",
        "    for file in text_files:\n",
        "      with open(file, 'r') as f:\n",
        "        tags = [t.strip() for t in f.read().split(\",\")]\n",
        "      top_tags.update(tags)\n",
        "\n",
        "    clear_output()\n",
        "    print(f\"üìä Tagging finalizado. Aqu√≠ est√°n las 50 im√°genes m√°s comunes en tu dataset:\")\n",
        "    print(\"\\n\".join(f\"{k} ({v})\" for k, v in top_tags.most_common(50)))\n",
        "  \n",
        "else:\n",
        "  !{venv_python} finetune/make_captions.py \\\n",
        "    {images_folder} \\\n",
        "    --beam_search \\\n",
        "    --max_data_loader_n_workers=2 \\\n",
        "    --batch_size=8 \\\n",
        "    --min_length={caption_min} \\\n",
        "    --max_length={caption_max} \\\n",
        "    --caption_extension=.txt \\\n",
        "    --recursive\n",
        "\n",
        "  if not get_ipython().__dict__['user_ns']['_exit_code']:\n",
        "    import random\n",
        "    for root, dirs, files in os.walk(images_folder):\n",
        "      for file in files:\n",
        "        if file.lower().endswith(\".txt\"):\n",
        "          text_files.append(os.path.join(root, file))\n",
        "    sample = []\n",
        "    for txt in random.sample(captions, min(10, len(captions))):\n",
        "      with open(os.path.join(images_folder, txt), 'r') as f:\n",
        "        sample.append(f.read())\n",
        "\n",
        "    clear_output()\n",
        "    print(f\"üìä Captioning finalizado. Aqu√≠ hay {len(sample)} ejemplos de descripciones en tu dataset:\")\n",
        "    print(\"\".join(sample))\n",
        "\n",
        "os.chdir(root_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WBFik7accyDz"
      },
      "outputs": [],
      "source": [
        "if \"step1_installed_flag\" not in globals():\n",
        "  raise Exception(\"Por favor usa el paso 1 primero.\")\n",
        "\n",
        "#@markdown ### 5Ô∏è‚É£ Editar las tags\n",
        "#@markdown Paso opcional para tags de anime. Puedes correr este paso cuantas veces quieras. <p>\n",
        "\n",
        "#@markdown A√±adir una palabra de activaci√≥n a tu Lora, √∫til para mejorar el entrenamiento y usarlo en tus prompts. En el entrenamiento debes poner `keep_tokens` igual a 1.<p>\n",
        "#@markdown Si quitas tags comunes como el color de pelo/ojos √©stas ser√°n \"absorbidas\" por tu palabra de activaci√≥n.\n",
        "palabra_de_activacion = \"\" #@param {type:\"string\"}\n",
        "global_activation_tag = palabra_de_activacion\n",
        "quitar_tags = \"\" #@param {type:\"string\"}\n",
        "remove_tags = quitar_tags\n",
        "#@markdown <p>&nbsp;<p> En esta zona avanzada puedes realizar reemplazos o combinaciones de tags para as√≠ mejorar su calidad. Puedes reemplazar 1 tag por varias, o varias por 1, o una por otra, etc. Tambi√©n puedes a√±adir palabras de activaci√≥n espec√≠ficas.\n",
        "buscar_tags = \"\" #@param {type:\"string\"}\n",
        "search_tags = buscar_tags\n",
        "reemplazar_con = \"\" #@param {type:\"string\"}\n",
        "replace_with = reemplazar_con\n",
        "modo_de_busqueda = \"OR (puede tener cualquiera)\" #@param [\"OR (puede tener cualquiera)\", \"AND (debe tener todo)\"]\n",
        "search_mode = modo_de_busqueda\n",
        "tag_nueva_se_convierte_en_palabra_de_activacion = False #@param {type:\"boolean\"}\n",
        "new_becomes_activation_tag = tag_nueva_se_convierte_en_palabra_de_activacion\n",
        "#@markdown Estas pueden ser √∫tiles a veces. Ten cuidado, pueden quitar las palabras de activaci√≥n previas.\n",
        "ordenar_alfabeticamente = False #@param {type:\"boolean\"}\n",
        "sort_alphabetically = ordenar_alfabeticamente\n",
        "quitar_duplicados = False #@param {type:\"boolean\"}\n",
        "remove_duplicates = quitar_duplicados\n",
        "\n",
        "def split_tags(tagstr):\n",
        "  return [s.strip() for s in tagstr.split(\",\") if s.strip()]\n",
        "\n",
        "activation_tag_list = split_tags(global_activation_tag)\n",
        "remove_tags_list = split_tags(remove_tags)\n",
        "search_tags_list = split_tags(search_tags)\n",
        "replace_with_list = split_tags(replace_with)\n",
        "replace_new_list = [t for t in replace_with_list if t not in search_tags_list]\n",
        "\n",
        "replace_with_list = [t for t in replace_with_list if t not in replace_new_list]\n",
        "replace_new_list.reverse()\n",
        "activation_tag_list.reverse()\n",
        "\n",
        "remove_count = 0\n",
        "replace_count = 0\n",
        "\n",
        "text_files = []\n",
        "for root, dirs, files in os.walk(images_folder):\n",
        "  for file in files:\n",
        "    if file.lower().endswith(\".txt\"):\n",
        "      text_files.append(os.path.join(root, file))\n",
        "\n",
        "for txt in text_files:\n",
        "\n",
        "  with open(os.path.join(images_folder, txt), 'r') as f:\n",
        "    tags = [s.strip() for s in f.read().split(\",\")]\n",
        "\n",
        "  if remove_duplicates:\n",
        "    tags = list(set(tags))\n",
        "  if sort_alphabetically:\n",
        "    tags.sort()\n",
        "\n",
        "  for rem in remove_tags_list:\n",
        "    if rem in tags:\n",
        "      remove_count += 1\n",
        "      tags.remove(rem)\n",
        "\n",
        "  if \"AND\" in search_mode and all(r in tags for r in search_tags_list) \\\n",
        "      or \"OR\" in search_mode and any(r in tags for r in search_tags_list):\n",
        "    replace_count += 1\n",
        "    for rem in search_tags_list:\n",
        "      if rem in tags:\n",
        "        tags.remove(rem)\n",
        "    for add in replace_with_list:\n",
        "      if add not in tags:\n",
        "        tags.append(add)\n",
        "    for new in replace_new_list:\n",
        "      if new_becomes_activation_tag:\n",
        "        if new in tags:\n",
        "          tags.remove(new)\n",
        "        tags.insert(0, new)\n",
        "      else:\n",
        "        if new not in tags:\n",
        "          tags.append(new)\n",
        "\n",
        "  for act in activation_tag_list:\n",
        "    if act in tags:\n",
        "      tags.remove(act)\n",
        "    tags.insert(0, act)\n",
        "\n",
        "  with open(os.path.join(images_folder, txt), 'w') as f:\n",
        "    f.write(\", \".join(tags))\n",
        "\n",
        "if remove_tags:\n",
        "  print(f\"\\nüöÆ Se han quitado {remove_count} tags.\")\n",
        "if search_tags:\n",
        "  print(f\"\\nüí´ Se han hecho {replace_count} reemplazos.\")\n",
        "print(\"\\n‚úÖ ¬°Listo!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HuJB7BGAyZCw"
      },
      "outputs": [],
      "source": [
        "#@markdown ### 6Ô∏è‚É£  Listo\n",
        "#@markdown Ahora debes estar listo para [entrenar tu Lora](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Spanish_Lora_Trainer.ipynb).\n",
        "\n",
        "from IPython.display import Markdown, display\n",
        "display(Markdown(f\"ü¶Ä [Click aqu√≠ para abrir el colab de entrenamiento](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Spanish_Lora_Trainer.ipynb) \"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDB9GXRONfiU"
      },
      "source": [
        "## *Ô∏è‚É£ Extras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xEsqOglcc6hA"
      },
      "outputs": [],
      "source": [
        "if \"step1_installed_flag\" not in globals():\n",
        "  raise Exception(\"Por favor usa el paso 1 primero.\")\n",
        "\n",
        "#@markdown ### üìà Analizar tags\n",
        "#@markdown Volver a ver las tags m√°s comunes en tus im√°genes.\n",
        "ver_top = 50 #@param {type:\"number\"}\n",
        "show_top_tags = ver_top\n",
        "\n",
        "text_files = []\n",
        "for root, dirs, files in os.walk(images_folder):\n",
        "  for file in files:\n",
        "    if file.lower().endswith(\".txt\"):\n",
        "      text_files.append(os.path.join(root, file))\n",
        "\n",
        "from collections import Counter\n",
        "top_tags = Counter()\n",
        "for file in text_files:\n",
        "  with open(file, 'r') as f:\n",
        "    tags = [t.strip() for t in f.read().split(\",\")]\n",
        "  top_tags.update(tags)\n",
        "\n",
        "print(f\"üìä Tus {show_top_tags} tags m√°s comunes:\")\n",
        "for k, v in top_tags.most_common(show_top_tags):\n",
        "  print(f\"{k} ({v})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hcAHDi3zPjtg"
      },
      "outputs": [],
      "source": [
        "#@markdown ### üìÇ Extraer datos\n",
        "#@markdown Es lento subir muchos archivos peque√±os, si quieres puedes subir un zip y extraerlo aqu√≠.\n",
        "zip = \"/content/drive/MyDrive/Loras/warrior.zip\" #@param {type:\"string\"}\n",
        "extract_to = \"/content/drive/MyDrive/Loras/ejemplo/dataset\" #@param {type:\"string\"}\n",
        "\n",
        "import os, zipfile\n",
        "\n",
        "if not os.path.exists('/content/drive'):\n",
        "  from google.colab import drive\n",
        "  print(\"üìÇ Connecting to Google Drive...\")\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "os.makedirs(extract_to, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip, 'r') as f:\n",
        "  f.extractall(extract_to)\n",
        "\n",
        "print(\"‚úÖ Done\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7AdGcZRyPmtm"
      },
      "outputs": [],
      "source": [
        "#@markdown ### üî¢ Contar archivos\n",
        "#@markdown Google Drive hace imposible contar los archivos en una carpeta, por lo que aqu√≠ puedes ver la cantidad de archivos en carpetas y subcarpetas.\n",
        "carpeta = \"/content/drive/MyDrive/Loras\" #@param {type:\"string\"}\n",
        "folder = carpeta\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "if not os.path.exists('/content/drive'):\n",
        "    print(\"üìÇ Connecting to Google Drive...\\n\")\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "tree = {}\n",
        "exclude = (\"_logs\", \"/output\")\n",
        "for i, (root, dirs, files) in enumerate(os.walk(folder, topdown=True)):\n",
        "  dirs[:] = [d for d in dirs if all(ex not in d for ex in exclude)]\n",
        "  images = len([f for f in files if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))])\n",
        "  captions = len([f for f in files if f.lower().endswith(\".txt\")])\n",
        "  others = len(files) - images - captions\n",
        "  path = root[folder.rfind(\"/\")+1:]\n",
        "  tree[path] = None if not images else f\"{images:>4} images | {captions:>4} captions |\"\n",
        "  if tree[path] and others:\n",
        "    tree[path] += f\" {others:>4} other files\"\n",
        "\n",
        "pad = max(len(k) for k in tree)\n",
        "print(\"\\n\".join(f\"üìÅ{k.ljust(pad)} | {v}\" for k, v in tree.items() if v))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FnN-rD4m_l0L"
      },
      "outputs": [],
      "source": [
        "if \"step1_installed_flag\" not in globals():\n",
        "  raise Exception(\"Please run step 1 first!\")\n",
        "\n",
        "from PIL import Image\n",
        "import os\n",
        "Image.MAX_IMAGE_PIXELS = None\n",
        "\n",
        "#@markdown ### üñºÔ∏è Reducir tama√±o de im√°genes\n",
        "#@markdown Esto convertir√° todas las im√°genes en la carpeta del proyecto a jpeg, reduciendo el tama√±o sin afectar mucho la calidad. Esto tambi√©n puede solucionar algunos errores.\n",
        "location = images_folder\n",
        "\n",
        "for dir in [d[0] for d in os.walk(location)]:\n",
        "    os.chdir(dir)\n",
        "    converted = False\n",
        "    for file_name in list(os.listdir(\".\")):\n",
        "        try:\n",
        "            # Convert png to jpeg\n",
        "            if file_name.endswith(\".png\"):\n",
        "                if not converted:\n",
        "                    print(f\"Converting {dir}\")\n",
        "                    converted = True\n",
        "                im = Image.open(file_name)\n",
        "                im = im.convert(\"RGB\")\n",
        "                new_file_name = os.path.splitext(file_name)[0] + \".jpeg\"\n",
        "                im.save(new_file_name, quality=95)\n",
        "                os.remove(file_name)\n",
        "                file_name = new_file_name\n",
        "            # Resize large jpegs\n",
        "            if file_name.endswith((\".jpeg\", \".jpg\")) and os.path.getsize(file_name) > 2000000:\n",
        "                if not converted:\n",
        "                    print(f\"Converting {dir}\")\n",
        "                    converted = True\n",
        "                im = Image.open(file_name)\n",
        "                im = im.resize((int(im.width/2), int(im.height/2)))\n",
        "                im.save(file_name, quality=95)\n",
        "            # Rename jpg to jpeg\n",
        "            if file_name.endswith(\".jpg\"):\n",
        "                if not converted:\n",
        "                    print(f\"Converting {dir}\")\n",
        "                new_file_name = os.path.splitext(file_name)[0] + \".jpeg\"\n",
        "                os.rename(file_name, new_file_name)\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while processing {file_name}: {e}\")\n",
        "    if converted:\n",
        "        print(f\"Converted {dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "l0tzRu6xBqj9"
      },
      "outputs": [],
      "source": [
        "if \"step1_installed_flag\" not in globals():\n",
        "  raise Exception(\"Por favor usa el paso 1 primero.\")\n",
        "\n",
        "#@markdown ### üöÆ Limpiar carpeta\n",
        "#@markdown Cuidado, borra todos los archivos que no sean im√°genes de la carpeta del proyecto.\n",
        "\n",
        "!find {images_folder} -type f ! \\( -name '*.png' -o -name '*.jpg' -o -name '*.jpeg' \\) -delete"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
